{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0c2255a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "\n",
        "@triton.jit\n",
        "def vector_add_kernel(a, b, c, n_elements, BLOCK_SIZE: tl.constexpr):\n",
        "    pid = tl.program_id(0)\n",
        "    offs = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offs < n_elements\n",
        "    a_vals = tl.load(a + offs, mask=mask, other=0.0)\n",
        "    b_vals = tl.load(b + offs, mask=mask, other=0.0)\n",
        "    c_vals = a_vals + b_vals\n",
        "    tl.store(c + offs, c_vals, mask=mask)\n",
        "\n",
        "\n",
        "# a, b, c are CUDA tensors\n",
        "def solve(a: torch.Tensor, b: torch.Tensor, c: torch.Tensor, n: int):\n",
        "    assert a.is_cuda and b.is_cuda and c.is_cuda, \"All tensors must be on CUDA\"\n",
        "    assert a.is_contiguous() and b.is_contiguous() and c.is_contiguous(), \"Tensors must be contiguous\"\n",
        "    assert a.numel() >= n and b.numel() >= n and c.numel() >= n, \"n exceeds tensor size\"\n",
        "\n",
        "    block_size = 1024\n",
        "    grid = (triton.cdiv(n, block_size),)\n",
        "    vector_add_kernel[grid](a, b, c, n, BLOCK_SIZE=block_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "24a265a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All Triton vector-add tests passed.\n"
          ]
        }
      ],
      "source": [
        "def run_vector_add_tests():\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"CUDA GPU is required to run Triton tests\")\n",
        "\n",
        "    torch.manual_seed(0)\n",
        "    test_sizes = [1, 17, 1023, 1024, 1025, 4096, 1000003]\n",
        "    test_dtypes = [torch.float32, torch.float16]\n",
        "\n",
        "    for dtype in test_dtypes:\n",
        "        for n in test_sizes:\n",
        "            a = torch.randn(n, device=\"cuda\", dtype=dtype)\n",
        "            b = torch.randn(n, device=\"cuda\", dtype=dtype)\n",
        "            c = torch.empty_like(a)\n",
        "\n",
        "            solve(a, b, c, n)\n",
        "            expected = a + b\n",
        "\n",
        "            atol = 1e-2 if dtype == torch.float16 else 1e-5\n",
        "            rtol = 1e-2 if dtype == torch.float16 else 1e-5\n",
        "            assert torch.allclose(c, expected, atol=atol, rtol=rtol), (\n",
        "                f\"Mismatch for dtype={dtype}, n={n}\"\n",
        "            )\n",
        "\n",
        "    # Quick smoke test on a larger tensor\n",
        "    n = 1_000_000\n",
        "    a = torch.randn(n, device=\"cuda\", dtype=torch.float32)\n",
        "    b = torch.randn(n, device=\"cuda\", dtype=torch.float32)\n",
        "    c = torch.empty_like(a)\n",
        "    solve(a, b, c, n)\n",
        "    assert torch.allclose(c, a + b, atol=1e-5, rtol=1e-5)\n",
        "\n",
        "    print(\"All Triton vector-add tests passed.\")\n",
        "\n",
        "\n",
        "run_vector_add_tests()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc5832be",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
