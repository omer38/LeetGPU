{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a2408252",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n",
        "\n",
        "\n",
        "@triton.jit\n",
        "def reverse_kernel(input, N, BLOCK_SIZE: tl.constexpr):\n",
        "    pid = tl.program_id(0)\n",
        "    offsets = pid * BLOCK_SIZE + tl.arange(0, BLOCK_SIZE)\n",
        "    mask = offsets < N // 2                          # only first half\n",
        "\n",
        "    a = tl.load(input + offsets, mask=mask)          # load left side\n",
        "    reverse_offsets = N - 1 - offsets\n",
        "    b = tl.load(input + reverse_offsets, mask=mask)  # load right side\n",
        "\n",
        "    tl.store(input + reverse_offsets, a, mask=mask)  # write left → right\n",
        "    tl.store(input + offsets, b, mask=mask)          # write right → left\n",
        "\n",
        "\n",
        "# input is a tensor on the GPU\n",
        "def solve(input: torch.Tensor, N: int):\n",
        "    BLOCK_SIZE = 1024\n",
        "    n_blocks = triton.cdiv(N // 2, BLOCK_SIZE)\n",
        "    grid = (n_blocks,)\n",
        "\n",
        "    reverse_kernel[grid](input, N, BLOCK_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2213679c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All reverse kernel tests passed.\n"
          ]
        }
      ],
      "source": [
        "def _reference_reverse(x: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.flip(x, dims=[0])\n",
        "\n",
        "\n",
        "def run_reverse_tests():\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"CUDA GPU is required to run Triton tests\")\n",
        "\n",
        "    test_sizes = [0, 1, 2, 3, 31, 32, 33, 1023, 1024, 1025, 1000001]\n",
        "    test_dtypes = [torch.float32, torch.int64]\n",
        "\n",
        "    for dtype in test_dtypes:\n",
        "        for n in test_sizes:\n",
        "            if dtype.is_floating_point:\n",
        "                x = torch.randn(n, device=\"cuda\", dtype=dtype)\n",
        "            else:\n",
        "                x = torch.randint(-1000, 1000, (n,), device=\"cuda\", dtype=dtype)\n",
        "\n",
        "            expected = _reference_reverse(x).clone()\n",
        "            solve(x, n)\n",
        "\n",
        "            if dtype.is_floating_point:\n",
        "                ok = torch.allclose(x, expected, atol=1e-5, rtol=1e-5)\n",
        "            else:\n",
        "                ok = torch.equal(x, expected)\n",
        "\n",
        "            assert ok, f\"reverse mismatch for dtype={dtype}, n={n}\"\n",
        "\n",
        "    # Deterministic sanity case\n",
        "    x = torch.tensor([1, 2, 3, 4, 5], device=\"cuda\", dtype=torch.int64)\n",
        "    solve(x, x.numel())\n",
        "    assert torch.equal(x, torch.tensor([5, 4, 3, 2, 1], device=\"cuda\", dtype=torch.int64))\n",
        "\n",
        "    print(\"All reverse kernel tests passed.\")\n",
        "\n",
        "\n",
        "run_reverse_tests()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f5078b1",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
